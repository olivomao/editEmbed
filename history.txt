# tag TBD indicates things to be improved in the codes
# for example, embedding_cgk.py #load, MAXLEN, transform deprecated
#
# debug tip: fix rand seed ==> check np.isnan(loss) ==> before this iteration, enable tfdbg and check tensors w/ inf or nan

2018.05.15

summary: add support for dependant (si_1, si_2) where si_2 is obtained from si_1 through an indel channel

batch_test.py
- add ins/del/sub for batch_test_data

file_structure.txt
- add s_i_type for siamese_seq2seq format

indel_channel.py
- wrap sim_seq

simulate_data.py
- gen_siamese_seq2seq: explicit input args; 
                       support both independent and dependent (indel channel) (si_1, si_2) pairs

2018.05.15

summary: add data pipeline and train framework for siamese_seq2seq

batch_test.py
- add batch_test_train_1job_siamese_seq2seq

edit_dist.py
- use absolute edit distance (unnormalized)

file_structure.txt
- add siamese_seq2seq format

simulate_data.py
- gen_siamese_seq2seq
- proj_hamming_dist add an option for normalize

storage_structure.txt
- add siamese_seq2seq storage

train.py
- add prepare_data_siamese_seq2seq
- add SiameseSeq2Seq_BatchedInput
- add train_siamese_seq2seq
- add show_hist


2018.05.11

summary: add validation support for training seq2seq architecture

file_structure.txt
- add loss_log format for seq2seq training

model_enc_dec.py
- make the code cleaner and support both train and infer

train.py
- add plot_log2 for log dump during seq2seq training
- modify prepare_minibatch_seq2seq to support infer batch size
- add calc_validation_loss to calculate avg hamming loss b/w ref_seq_ids and predicted_seq_ids with shape=(batch size, time length) (they may have different time length)
- refine the train_seq2seq loop

2018.05.09

batch_test:
- train seq2seq

file_structure:
- add seq2seq_pair, seq2ids, vocab formats

inference:
- tried atention mechanism (currently disabled)

simulate_data:
- gen_seq2seq

storage_structure
- add seq2seq related files

train
- add seq2seq train related codes

model_enc_dec.py
- new seq2seq model

2018.04.10


summary: add validation loss. shuffle train and validation data. dump loss curves.

file_structure.txt
- add loss_log format (to dump training loss and validation loss fig)

storage_structure.txt
- add log.txt and log.png for training

proc_data.py
- shuffle x1,x2,y
- split_train_validation to provide validation data


train.py
- support plot loss (training and validation)
- also calculate validation

2018.04.04

summary: complete batch_test_eval (esp select and debug ckpt)

batch_test.py
- use ';' to seperate param combinations
- add select_ckpt (for a set of params, there can be several ckpt)

inference.py
- norm path for Predict's model_prefix, to avoid error when restoring saved tf model


2018.03.30

summary: set rand seed 0, add tfdbg option and do gradient clipping

inference.py
- siamese init: rand seed 0 (for debug purpose and reproducibility)

proc_data.py
- load2: rand seed 0 (for debug purpose and reproducibility)

train.py
- add debug option (tfdbg before sess.run and check loss nan)
- grad to be clipped by norm

2018.03.22

summary: apply normalization on edit dist and lstm layer output. balance number of different types of pairs.

edit_dist.py
- use normed dist

evaluation.py
- fix a bug for draw_histogram when there's only one dist metric (only one subplot)

inference.py
- hidden layer output normalized

proc_data.py
- rand sample type 1 pairs so that number of type 0 and type 1 pairs are similar.

util.py
- fix a bug for iterCounter.inc() (to avoid zero division)

2018.03.21

summary: support cgk embedding

simulate_data.py
- add support for cgk embedding (both binary and dna seq; rand seq same for both seqs of a pair)

2018.03.21

summary: support export_embed. e.g. x==>f(x)

evaluation.py
- add export_embedding

file_structure.txt
- add embed_fa

inference.py
- siamese: name output1 and output2 so that embedding can be extracted
- Predict: add get_embed method

test_sim_data_eval.sh
- add export_embedding related script


2018.03.21

summary:
add code comments

train.py
- prepare_data: remove tf.FLAGS

simulate_data.py
- add comments

proc_data.py
- delete transform and load2 (w/o seq2nn)
- add code comments

inference.py
- remove predict(...
- add code comments

2018.03.20

evaluation.py
- handle dist==nan issue
- add code comments

2018.03.19

summary:
- improve whole framework: consistent pipeline; support nn prediction and downstream analysis (histogram and roc); use seq2nn to handle data transform for both train and inference etc

train.py
- add prepare data (not using tf.FLAGS)
- better console interface

simulate_data.py
- pairwise dist file supports multiple dist types (e.g. calc_non_learned_dist)
- calc_dist_1thread: use seq2nn; pt to set max_num_dist_1thread for quick verification of code flow
- calc_dist_Nthread: related changes based on calc_dist_1thread

proc_data.py
- disable transform (e.g. global variables usage)

inference.py
- maxlen and blocklen no longer global variables; to be saved into model and restored later
- add Predict, seq2nn for prediction based on trained model
- add Fa_tseq class for prediction based on trained model
- load: apply seq2nn
- load2: use args and seq2nn

2018.03.08

indel_channel.py
- support bin/dna seq
- support calc num of sampled seq per cluster by tot_num*weigt or fixed copy_num

simulate_data.py
- weight normalized
- sample from cluster using 1 thread or multiple threads

util.py
- add run_cmds
- add split_fa_file and merge_files
